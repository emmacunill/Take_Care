{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import time\n",
    "import concurrent.futures\n",
    "from deep_translator import GoogleTranslator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TRANSLATING** #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''message_history=[{\"role\": \"system\", \"content\": \"Translate this into Spanish, Portuguese, Italian\"}\n",
    "  ]\n",
    "print(\"Write a phrase to translate to Spanish, Portuguese and Italian: \")\n",
    "\n",
    "while(True):\n",
    "    message_history = gpt_response(input(\"> \"), message_history,temperature=0.3,max_tokens=60)\n",
    "    print(message_history[-1][\"content\"])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import openai\n",
    "import pandas as pd\n",
    "\n",
    "# Set up your OpenAI API key\n",
    "openai.api_key = 'YOUR_OPENAI_API_KEY'\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'message' is the column with text\n",
    "def translate_with_gpt(df):\n",
    "    translations = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        message = row['message']\n",
    "        prompt = f\"Translate the following text into English: '{message}'\"\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"text-davinci-002\",  # You may need to adjust the engine choice\n",
    "            prompt=prompt,\n",
    "            max_tokens=100  # You may need to adjust the maximum number of tokens\n",
    "        )\n",
    "        translated_message = response['choices'][0]['text'].strip()\n",
    "        translations.append(translated_message)\n",
    "\n",
    "    df['translated_message'] = translations\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "# df = ...  # Your DataFrame\n",
    "df = translate_with_gpt(df)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"token\")\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "missatges= pd.read_csv(\"../data/translation/missatges.csv\")\n",
    "completo = pd.read_csv(\"../data/translation/completo.csv\")\n",
    "messages = pd.read_csv(\"../data/translation/message copia.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To greet you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It s just that I still have to eat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Okaaaay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              message\n",
       "0                               Audio\n",
       "1                               Audio\n",
       "2                        To greet you\n",
       "3  It s just that I still have to eat\n",
       "4                             Okaaaay"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef translate_with_gpt(df):\\n    translations = []\\n    total_tokens_used = 0\\n\\n    for index, row in df.iterrows():\\n        message = row[\\'message\\']\\n        prompt = f\"Translate the following text into English, make it grammatically correct: \\'{message}\\'\"\\n\\n        # Calculate the number of tokens in the prompt\\n        prompt_tokens = len(openai.Completion.create(engine=\"text-davinci-003\", prompt=prompt)[\\'choices\\'][0][\\'text\\'].split())\\n\\n        # Check if adding the prompt tokens exceeds the allowed limit\\n        if total_tokens_used + prompt_tokens <= 20000:\\n            response = openai.Completion.create(\\n                engine=\"text-davinci-002\",\\n                prompt=prompt,\\n                max_tokens=100\\n            )\\n            translated_message = response[\\'choices\\'][0][\\'text\\'].strip()\\n            translations.append(translated_message)\\n            \\n            # Update the total tokens used\\n            total_tokens_used += prompt_tokens\\n        else:\\n            # If adding the prompt tokens exceeds the limit, break the loop\\n            print(\"Exceeded token limit. Stopping translation.\")\\n            break\\n\\n    df[\\'translated_message\\'] = translations\\n    return df\\n\\n# Example usage\\ncompleto = pd.DataFrame({\\'message\\': [\\'Hola\\', \\'Cómo estás\\', \\'Adiós\\']})\\ndf_translated = translate_with_gpt(completo)\\nprint(df_translated)'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def translate_with_gpt(df):\n",
    "    translations = []\n",
    "    total_tokens_used = 0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        message = row['message']\n",
    "        prompt = f\"Translate the following text into English, make it grammatically correct: '{message}'\"\n",
    "\n",
    "        # Calculate the number of tokens in the prompt\n",
    "        prompt_tokens = len(openai.Completion.create(engine=\"text-davinci-003\", prompt=prompt)['choices'][0]['text'].split())\n",
    "\n",
    "        # Check if adding the prompt tokens exceeds the allowed limit\n",
    "        if total_tokens_used + prompt_tokens <= 20000:\n",
    "            response = openai.Completion.create(\n",
    "                engine=\"text-davinci-002\",\n",
    "                prompt=prompt,\n",
    "                max_tokens=100\n",
    "            )\n",
    "            translated_message = response['choices'][0]['text'].strip()\n",
    "            translations.append(translated_message)\n",
    "            \n",
    "            # Update the total tokens used\n",
    "            total_tokens_used += prompt_tokens\n",
    "        else:\n",
    "            # If adding the prompt tokens exceeds the limit, break the loop\n",
    "            print(\"Exceeded token limit. Stopping translation.\")\n",
    "            break\n",
    "\n",
    "    df['translated_message'] = translations\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "completo = pd.DataFrame({'message': ['Hola', 'Cómo estás', 'Adiós']})\n",
    "df_translated = translate_with_gpt(completo)\n",
    "print(df_translated)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def translate_with_gpt(df):\\n    translations = []\\n\\n    for index, row in df.iterrows():\\n        message = row[\\'message\\']\\n        prompt = f\"Translate the following text into English, make it grammatically correct: \\'{message}\\'\"\\n        response = openai.Completion.create(\\n            engine=\"text-davinci-002\",  # You may need to adjust the engine choice\\n            prompt=prompt,\\n            max_tokens=100  # You may need to adjust the maximum number of tokens\\n        )\\n        translated_message = response[\\'choices\\'][0][\\'text\\'].strip()\\n        translations.append(translated_message)\\n\\n    df[\\'translated_message\\'] = translations\\n    return df\\n\\ndf = translate_with_gpt(completo)'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def translate_with_gpt(df):\n",
    "    translations = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        message = row['message']\n",
    "        prompt = f\"Translate the following text into English, make it grammatically correct: '{message}'\"\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"text-davinci-002\",  # You may need to adjust the engine choice\n",
    "            prompt=prompt,\n",
    "            max_tokens=100  # You may need to adjust the maximum number of tokens\n",
    "        )\n",
    "        translated_message = response['choices'][0]['text'].strip()\n",
    "        translations.append(translated_message)\n",
    "\n",
    "    df['translated_message'] = translations\n",
    "    return df\n",
    "\n",
    "df = translate_with_gpt(completo)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def translate_with_gpt(df):\\n   translations = []\\n\\n   # Ensure that the total_tokens variable tracks the cumulative tokens used\\n   total_tokens = 0\\n\\n   for index, row in df.iterrows():\\n       message = row[\\'message\\']\\n\\n       # Calculate the number of tokens in the prompt\\n       prompt_tokens = len(f\"Translate the following text into English, make it grammatically correct and instead of apostrophes put spaces: \\'{message}\\'\")\\n\\n       # Check if adding the prompt tokens would exceed the TPM limit\\n       if total_tokens + prompt_tokens > 4096:  # Maximum tokens for gpt-3.5-turbo\\n           # If it exceeds, wait for a minute to reset the token count\\n           time.sleep(60)\\n           total_tokens = 0\\n\\n       # Make the API call using gpt-3.5-turbo\\n       response = openai.Completion.create(\\n           engine=\"text-davinci-003\",  # GPT-3.5-turbo engine\\n           prompt=f\"Translate the following text into English, make it grammatically correct and instead of apostrophes put spaces: \\'{message}\\'\",\\n           max_tokens=4096  # Maximum tokens for gpt-3.5-turbo\\n       )\\n\\n       # Extract the translated message from the API response\\n       translated_message = response[\\'choices\\'][0][\\'text\\'].strip()\\n\\n       # Update the total tokens count\\n       total_tokens += prompt_tokens + response[\\'usage\\'][\\'total_tokens\\']\\n\\n       translations.append(translated_message)\\n       print(f\\'{index} row has been translated\\')\\n\\n   df[\\'translated_message\\'] = translations\\n   return df\\n\\n# Example usage\\ndf = translate_with_gpt(completo)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Replace with your OpenAI API key\n",
    "\n",
    "'''def translate_with_gpt(df):\n",
    "    translations = []\n",
    "\n",
    "    # Ensure that the total_tokens variable tracks the cumulative tokens used\n",
    "    total_tokens = 0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        message = row['message']\n",
    "\n",
    "        # Calculate the number of tokens in the prompt\n",
    "        prompt_tokens = len(f\"Translate the following text into English, make it grammatically correct and instead of apostrophes put spaces: '{message}'\")\n",
    "\n",
    "        # Check if adding the prompt tokens would exceed the TPM limit\n",
    "        if total_tokens + prompt_tokens > 4096:  # Maximum tokens for gpt-3.5-turbo\n",
    "            # If it exceeds, wait for a minute to reset the token count\n",
    "            time.sleep(60)\n",
    "            total_tokens = 0\n",
    "\n",
    "        # Make the API call using gpt-3.5-turbo\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"text-davinci-003\",  # GPT-3.5-turbo engine\n",
    "            prompt=f\"Translate the following text into English, make it grammatically correct and instead of apostrophes put spaces: '{message}'\",\n",
    "            max_tokens=4096  # Maximum tokens for gpt-3.5-turbo\n",
    "        )\n",
    "\n",
    "        # Extract the translated message from the API response\n",
    "        translated_message = response['choices'][0]['text'].strip()\n",
    "\n",
    "        # Update the total tokens count\n",
    "        total_tokens += prompt_tokens + response['usage']['total_tokens']\n",
    "\n",
    "        translations.append(translated_message)\n",
    "        print(f'{index} row has been translated')\n",
    "\n",
    "    df['translated_message'] = translations\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "df = translate_with_gpt(completo)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def translate_single_message(message):\\n    response = openai.Completion.create(\\n        engine=\"text-davinci-003\",\\n        prompt=f\"Translate the following text into English, make it grammatically correct and instead of apostrophes put spaces: \\'{message}\\'\",\\n        max_tokens=4096\\n    )\\n\\n    translated_message = response[\\'choices\\'][0][\\'text\\'].strip()\\n    return translated_message\\n\\ndef translate_with_gpt_parallel(df, num_workers=4):\\n    translations = []\\n\\n    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\\n        results = list(executor.map(translate_single_message, df[\\'message\\']))\\n\\n    df[\\'translated_message\\'] = results\\n    return df\\n\\ndf = translate_with_gpt(completo)'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def translate_single_message(message):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=f\"Translate the following text into English, make it grammatically correct and instead of apostrophes put spaces: '{message}'\",\n",
    "        max_tokens=4096\n",
    "    )\n",
    "\n",
    "    translated_message = response['choices'][0]['text'].strip()\n",
    "    return translated_message\n",
    "\n",
    "def translate_with_gpt_parallel(df, num_workers=4):\n",
    "    translations = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        results = list(executor.map(translate_single_message, df['message']))\n",
    "\n",
    "    df['translated_message'] = results\n",
    "    return df\n",
    "\n",
    "df = translate_with_gpt(completo)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import pandas as pd\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# Translator initialization\n",
    "translator = GoogleTranslator(source='auto', target='en')\n",
    "\n",
    "def translate_text(text):\n",
    "    try:\n",
    "        return translator.translate(text)\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "# Apply translation to each message\n",
    "messages['translated'] = messages['message'].apply(translate_text)\n",
    "# Display the first few rows of the translated DataFrame\n",
    "messages.head()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensambeling models\n",
    "''' Hacer orimero que cada palabra de la columna messages sea una linea de un nuevo dataframe.\n",
    "mirar las palabras mas repetidas.\n",
    "Asociar valores a las palabras y crear dataframe\n",
    "en mi dataframe pero copia poner columna por cada tag que encuentre.\n",
    "despues a partir de aquí asociarle emociones\n",
    "y construir el modelo.'''\n",
    "\n",
    "'''NLP LEMMATIZATION\n",
    "generar nova columna per lemmatization stemming'''\n",
    "\n",
    "'''Trobar formula del sample minim que necessito per ser representatiu\n",
    "per agafar el sample random \n",
    "llistat emocions dataframe\n",
    "\n",
    "dels 1000 missatges anar un per un i classificar\n",
    "\n",
    "entreno sobre els 1000 per trobar el millor model\n",
    "\n",
    "entreno despres sobre tot el sample i despres ja li poso a tot el meu dataset\n",
    "\n",
    "fer bootstrapping i fer el m'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
